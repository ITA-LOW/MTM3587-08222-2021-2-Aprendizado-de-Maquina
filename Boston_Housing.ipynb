{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ITA-LOW/MTM3587-08222-2021-2-Aprendizado-de-Maquina/blob/main/Boston_Housing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSkKOyAJrE5O"
      },
      "source": [
        "# Projeto Boston Housing\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVl4sAri_GWH"
      },
      "source": [
        "## Objetivos do projeto\n",
        "* Descrição do conjunto de dados;\n",
        "* Separação do conjunto em treino e teste;\n",
        "* Visualização do conjunto de dados (análise exploratória básica);\n",
        "* Preparação do conjunto de dados;\n",
        "* Comparar ao menos 3 modelos de machine learning e algumas configuração de hiperparâmetros, justificando a escolha do melhor modelo;\n",
        "* Você deve ainda justificar a escolha da métrica utilizada;\n",
        "* Deve discutir a técnica utilizada para validar o modelo e deve explicar como que o seu modelo evita o \"snooping bias/data leakage\";\n",
        "* Fazer teste final para obter um erro aproximado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3TC2yxW__UA"
      },
      "source": [
        "##Roteiro\n",
        "1. Conhecendo o conjunto de dados;\n",
        "\n",
        "  1.1. Visualização dos dados;\n",
        "2. Implementando o algoritmo de regressão linear;\n",
        "\n",
        "  2.1. Analisando as métricas de performance do modelo;\n",
        "3. Implementando o algoritmo de SGDClassifier;\n",
        "\n",
        "  3.1 Analisando as métricas de performance do modelo;\n",
        "4. Implementando mais um algoritmo;\n",
        "\n",
        "  4.1 Analisando as métricas de performance do modelo;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYTeDfxKTZNz"
      },
      "source": [
        "#1. Conhecendo o conjunto de dados\n",
        "O Boston Housing é um conjunto de dados para prática de machine learning bastante explorado para fins educacionais. São constituição pode ser vista abaixo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4QfbPGSZrxBW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_boston\n",
        "boston = load_boston()\n",
        "#Apesar da mensagem alertando sobre problemas éticos no conjunto de dados\n",
        "#tentarei seguir a análise com esse dataset pois o conjunto sugerido\n",
        "#na mensagem não mostra a relação das features com o target!\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns #biblioteca para visualização de dados\n",
        "import matplotlib.pyplot as plt #biblioteca para criação de gráficos\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "jMWqBdpjZSOm"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfXrxxXXUc_p"
      },
      "source": [
        "Vamos analisar o conjunto de dados"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(boston)\n",
        "#o termo bunch pode ser interpretado como dicionário, ou seja, seus\n",
        "#dados são estruturados como dicionários (key:value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ft99vmkiYpw1",
        "outputId": "8f52e2ec-5f77-4c7b-ef29-68c197200c40"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sklearn.utils.Bunch"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "boston.keys()\n",
        "#retorna as chaves onde estão guardados os valores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CuXUubbobSWs",
        "outputId": "ecfd7bb5-e03d-407f-85fd-4863a2a616a5"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['data', 'target', 'feature_names', 'DESCR', 'filename', 'data_module'])"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(boston.DESCR)\n",
        "#a chave DESCR mostra como os dados estão organizados"
      ],
      "metadata": {
        "id": "wWJtpnssbodm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(boston.feature_names)\n",
        "#aqui é mostrado quais são as features, note que MEDV não está aqui\n",
        "#pois ela é nosso target (y)"
      ],
      "metadata": {
        "id": "RsC4qpD8cOKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = boston.data\n",
        "data.shape\n",
        "#aqui são os dados relacionais do conjunto, aloquei na variável \"data\" para \n",
        "#facilitar a construção do dataframe. Terá 506 linhas com 13 colunas"
      ],
      "metadata": {
        "id": "-f7ov79Qc-oV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Esse é o dataframe com as variáveis independentes ['CRIM', 'ZN', 'INDUS', '...]\n",
        "#que são relacionadas com o target [data]\n",
        "df_x = pd.DataFrame(data = data, columns = boston.feature_names)\n",
        "\n",
        "#Esse é o dataframe com as variáveis dependentes [target]\n",
        "df_y = pd.DataFrame(boston.target)\n",
        "\n",
        "#Os 2 dataframes foram mantidos separados para não haver snooping bias/data leakage"
      ],
      "metadata": {
        "id": "5xSlfHhlZU1X"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos conferir como ficou o dataframe df_x"
      ],
      "metadata": {
        "id": "DdG9aU-CbQ8a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_x.describe()\n",
        "#mostra as estatísticas principais do conjunto"
      ],
      "metadata": {
        "id": "8YcFHHkqbWUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_x.info()\n",
        "#info mostra o tipo de dados e se há algum valor nulo no dataset\n"
      ],
      "metadata": {
        "id": "87QFCiFGeyIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos conferir como ficou o dataframe df_y"
      ],
      "metadata": {
        "id": "209sVvIAJD_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#É possível ver valores que podem ser considerados outliers porém não\n",
        "#serão tratados, vamos ver como a máquina tratará esses valores\n",
        "df_y.boxplot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JRe6aWRiJC9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Visualização dos dados\n",
        "Uma forma interessante de conhecer os dados é trabalhando suas abstrações através de gráficos. Com um conjunto de dados volumoso é possível que certos padrões não possam ser identificados apenas olhando as estatísticas."
      ],
      "metadata": {
        "id": "0BshBlYTfFdd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Criei um dataframe com o target incluído para analisar como o target se\n",
        "#relaciona com as features. Não será usado para o modelo de ML\n",
        "DF_X = pd.DataFrame(data = data, columns= boston.feature_names)\n",
        "DF_X['PREÇO'] = boston.target\n",
        "sns.pairplot(DF_X)\n",
        "#Com essa distribuição podemos ver que existe uma visível correlação entre o \n",
        "#target e as features \"RM\" e \"LSTAT\". \n"
      ],
      "metadata": {
        "id": "RUaTlejifhnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Abaixo os gráficos de 'RM' e 'LSTAT' mostram boa distribuição gaussiana \n",
        "sns.displot(DF_X['RM'])\n",
        "sns.displot(DF_X['LSTAT'])\n",
        "\n"
      ],
      "metadata": {
        "id": "Z0fNmB_Um9cX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Implementando o algoritmo de regressão linear\n",
        "Vamos iniciar o modelo de regressão linear do SKlearn"
      ],
      "metadata": {
        "id": "hd44cJwIdd98"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Criando os conjuntos de treino e teste\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_x, df_y, test_size = 0.30, random_state=42)\n",
        "\n",
        "X_train.shape, X_test.shape #Mostra a distribuição dos pontos de dados"
      ],
      "metadata": {
        "id": "Yv0eVfPJdjgT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1f62ccc-1c7f-4edb-dc4a-cb6a2540abe5"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((354, 13), (152, 13))"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Vamos carregar o modelo da biblioteca\n",
        "from sklearn.linear_model import LinearRegression"
      ],
      "metadata": {
        "id": "-N9J8TcZe40N"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Vamos criar um objeto e instanciá-lo em LinearRegression\n",
        "from sklearn import linear_model\n",
        "reg = linear_model.LinearRegression()"
      ],
      "metadata": {
        "id": "FWhmkcF4f0f0"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Vamos ajustar o conjunto de treino ao modelo de regressão linear criado\n",
        "reg.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZFFlXcggGZu",
        "outputId": "8653b89b-e9b5-4874-fc1a-8d0357d0319a"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Realizando as predições dentro do conjunto de testes\n",
        "linear_pred = reg.predict(X_test)"
      ],
      "metadata": {
        "id": "IixWJuOjhljT"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.1. Analisando as métricas de performance do modelo"
      ],
      "metadata": {
        "id": "TI4PbenzyPgi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Verificando as métricas de desempenho\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "r2 = r2_score(y_test, linear_pred)\n",
        "mse = mean_squared_error(y_test, linear_pred)\n",
        "mae = mean_absolute_error(y_test, linear_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "print('\\nR2 = {} \\nMSE = {} \\nMAE = {} \\nRMSE = {}'.format(r2,mse,mae, rmse))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmheP88hrIuq",
        "outputId": "23399922-17a0-47d6-a6d4-48b0216b797d"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "R2 = 0.7112260057484974 \n",
            "MSE = 21.5174442311769 \n",
            "MAE = 3.1627098714573685 \n",
            "RMSE = 4.638689926172788\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "* <h2>Métricas</h2>\n",
        "1.  <h4>Coeficiente de determinação $R^2$</h4>\n",
        "O coeficiente de e determinação indica quanto a variável dependente $y$ pode ser explicada a partir do modelo de regressão. Varia de 0 a 1. No caso desse modelo, o valor de $R^2$ foi 0,71 ou 71% dos valores de $y$ puderam ser explicados pelo modelo. O $R^2$ é calculado da seguinte maneira: \n",
        "$$\\displaystyle R^{2} =1-\\frac{\\sum _{i=1}^{n}( y_i-\\hat{y_i})^{2}}{\\sum _{i=1}^{n}(\\hat{y_i} -\\overline{y_i})^{2}}$$ \n",
        "onde: $\\hat{y}-\\overline{y}$ é a diferença do valor previsto pelo valor médio real, que quanto menor, mais fiel a realidade estará o modelo.\n",
        "\n",
        "1. <h4>Erro quadrado médio</h4>O erro quadrado médio é a média da soma de todas as \"distâncias\" que o valor previsto $\\hat{y}$ ficou do valor real (por isso é dividido por $n$. Está ao quadrado pois alguns valores previstos ficam abaixo do valor real, ou seja, existem números negativos nessa soma que se não fossem corrigidos retornariam um MSE = 0. O MSE é calculado da seguinte forma:\n",
        "$$MSE=\\frac{1}{n} {\\sum\\limits _{i=1}^{n} (\\hat{y_i}-y_i)^2} $$\n",
        " Quanto menor esse valor, mais próximo nossa predição se aproximou do valor real. No caso desse modelo o MSE ficou em 21,5. É uma boa métrica mas precisa vir acompanhada do RMSE para que essa média reproduza os valores previstos na mesma dimensão dos valores reais.\n",
        "\n",
        "3. <h4>Raiz do MSE</h4> É a raiz quadrada do MSE, mostra o valor previsto na mesma dimensão do valor real. Nesse modelo, o RMSE foi de 4,6 o que significa que a máquina errou em U$4600 em média o valor do imóvel.\n",
        "\n",
        "2. <h4>Erro absoluto médio</h4>É a soma do módulo de todas as diferenças entre os valores reais menos os valores previstos divididos pela quantidade de amostras:\n",
        "$$MAE=\\frac{1}{n} {\\sum\\limits _{i=1}^{n} |y_i-\\hat{y_i}|} $$\n",
        "Esse valor também é uma métrica de desempenho por mostrar a média de erro entre o valor predito e o valor real. No caso desse modelo ficou em 3,16 o que é bem próximo do valor de MSE.\n"
      ],
      "metadata": {
        "id": "qvOM_01uycu0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Implementando o algoritmo de Regressão Ridge"
      ],
      "metadata": {
        "id": "WB8ESf3rEV9_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importando e instanciando\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_x, df_y, test_size = 0.30, random_state=42)\n",
        "\n",
        "from sklearn import linear_model\n",
        "rid = linear_model.Ridge(alpha=.001)\n",
        "rid.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzWHVf988XBb",
        "outputId": "99b92e18-ac1d-4b91-f576-bda39f3df282"
      },
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ridge(alpha=0.001)"
            ]
          },
          "metadata": {},
          "execution_count": 216
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Realiando as previsões\n",
        "Ridge_pred = rid.predict(X_test)"
      ],
      "metadata": {
        "id": "W8KJvKxqNac3"
      },
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Analisando as métricas\n",
        "ridge_r2_score = r2_score(y_test, Ridge_pred)\n",
        "print(ridge_r2_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEITkW5Gyngi",
        "outputId": "e7a189c4-26b2-45f3-952d-5155c15cc02e"
      },
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.711216928951723\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Analisando as métricas de performance do modelo"
      ],
      "metadata": {
        "id": "BXlW4A1hi90Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Vou testar alguns valores de alpha para verificar a performance\n",
        "lista_alpha=[0.0001, 0.001, 0.01, 0.1, 1, 10]\n",
        "r2=[]\n",
        "MSE=[]\n",
        "MAE=[]\n",
        "for alpha in lista_alpha:\n",
        "  rid = linear_model.Ridge(alpha = alpha)\n",
        "  rid.fit(X_train, y_train)\n",
        "  Ridge_pred = rid.predict(X_test)\n",
        "  r2.append(r2_score(y_test, Ridge_pred))\n",
        "  MSE.append(mean_squared_error(y_test, Ridge_pred))\n",
        "  MAE.append(mean_absolute_error(y_test, Ridge_pred))\n",
        "\n",
        "param = pd.DataFrame(list(zip(lista_alpha, r2, MSE, MAE)), columns=['alpha','r2','MSE','MAE'])\n",
        "param"
      ],
      "metadata": {
        "id": "iUURzfDGXNUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "É possível verificar que os valores mudam pouco em relação ao parâmetro de regularização alpha. Na regressão Ridge, alpha é um penalizador conhecido como L2, ajudando a evitar o sobreajuste do modelo. Quanto maior o valor de alpha, mais pesada é a penalização. Nesse modelo, mesmo com valores exponencialmente grandes, a performance da máquina em relação ao coeficiente de determinação se manteve por volta de 70%."
      ],
      "metadata": {
        "id": "xNfnxf7LbCAA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Implementando o algoritmo de Regressão Huber"
      ],
      "metadata": {
        "id": "iDyiXrFZiAaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Testando o algoritmo HuberRegressor\n",
        "from sklearn.linear_model import HuberRegressor\n",
        "lista_epsilon=[1, 1.2, 1.4, 1.6, 1.8, 2, 3]\n",
        "hub_r2=[]\n",
        "hub_MSE=[]\n",
        "hub_MAE=[]\n",
        "\n",
        "for e in lista_epsilon:\n",
        "  hub = HuberRegressor(epsilon = e)\n",
        "  hub.fit(X_train, y_train)\n",
        "  hub_pred = hub.predict(X_test)\n",
        "  hub_r2.append(r2_score(y_test, hub_pred))\n",
        "  hub_MSE.append(mean_squared_error(y_test, hub_pred))\n",
        "  hub_MAE.append(mean_absolute_error(y_test, hub_pred))\n",
        "\n",
        "paramh = pd.DataFrame(list(zip(lista_epsilon, hub_r2, hub_MSE, hub_MAE)), columns=['epsilon','r2','MSE','MAE'])\n",
        "paramh\n"
      ],
      "metadata": {
        "id": "_n3eH14Pd1nW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4.1 Analisando as métricas de performance do modelo\n",
        "\n",
        "Apesar de performance não ser parecida com a regressão linear e Ridge, esse algoritmo conseguiu bons resultados quando seu parâmetro épsilon é 1.4. Segundo a documentação do SKlearn, esse algoritmo tem por característica penalizar conjunto de dados com muitos outliers de maneira mais robusta que era o caso do Boston Housing."
      ],
      "metadata": {
        "id": "hddTPflfiMIz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. Métricas\n",
        "As métricas $R^2$, MAE e MSE são amplamente aplicadas em diversas áreas de conhecimento que utilizam dados estatísticos, são estudadas a muitos anos e, por isso, são muito confiáveis. A escolha dessas métricas se baseou nesse histórico."
      ],
      "metadata": {
        "id": "RklCnZSLjhnj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6. Considerações finais\n",
        "Após os testes realizados e comparando os resultados obtidos, o que melhor poderia performar no mundo real seria o Modelo de Regressão Linear que foi apresentado primeiro. Segundo o princípio da Navalha de Ockhan, o modelo mais simples mas que reproduz os mesmos resultados dos modelos mais complexos deve ser o melhor modelo.\n",
        "\n",
        "No entanto, o último modelo, HuberRegressor, que tem por característica penalizar mais fortemente conjunto de dados com possíveis outliers, também pode ser objeto de análise. "
      ],
      "metadata": {
        "id": "7RKTsLOakusY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#7. Referências\n",
        "1. https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.HuberRegressor.html#sklearn.linear_model.HuberRegressor\n",
        "\n",
        "2. https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression\n",
        "\n",
        "3. https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge\n",
        "\n",
        "4. MÜLLER, Andreas C.; GUIDO, Sarah. Introduction to Machine Learning with Python: a guide for data scientists. Sebastopol: O’reilly Media, 2016.\n",
        "\n",
        "5. https://github.com/EdsonCilos/mlcourse"
      ],
      "metadata": {
        "id": "biu7QB01l_0a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#8. Roteiro\n",
        "Seguindo o roteiro foi possível alcançar os seguintes objetivos:\n",
        "* Descrição do conjunto de dados ✔\n",
        "* Separação do conjunto em treino e teste ✔\n",
        "* Visualização do conjunto de dados (análise exploratória básica) ✔\n",
        "* Preparação do conjunto de dados ✔\n",
        "* Comparar ao menos 3 modelos de machine learning e algumas configuração de hiperparâmetros, justificando a escolha do melhor modelo ✔\n",
        "* Você deve ainda justificar a escolha da métrica utilizada ✔\n",
        "* Deve discutir a técnica utilizada para validar o modelo e deve explicar como que o seu modelo evita o \"snooping bias/data leakage\" ✔\n",
        "* Fazer teste final para obter um erro aproximado ✔"
      ],
      "metadata": {
        "id": "YbYddJu3pYme"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "jVl4sAri_GWH",
        "n3TC2yxW__UA",
        "cYTeDfxKTZNz",
        "hd44cJwIdd98",
        "WB8ESf3rEV9_",
        "BXlW4A1hi90Q"
      ],
      "name": "Boston Housing.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMliceWRE36zOyhw9E/cdOa",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}